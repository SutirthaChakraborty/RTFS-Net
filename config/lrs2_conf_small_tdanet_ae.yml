# Video network config
videonet:
    model_name: EncoderAE
    in_channels: 1
    base_channels: 4
    num_layers: 3
    pretrain: ../experiments/autoencoder/default/best_model.pth
audionet:
    n_src: 1
    pretrained_vout_chan: 1936                  # output from pretrained model

    video_bn_params:
      out_chan: 64
      kernel_size: 3
      padding: 1

    audio_bn_params:
      out_chan: 512
      kernel_size: 1

    enc_dec_params:
      encoder_type: ConvolutionalEncoder
      decoder_type: ConvolutionalDecoder
      out_chan: 512
      kernel_size: 21
      stride: 10
      bias: False
      act_type: 
      norm_type: gLN
      layers: 1
      
    audio_params:
      audio_net: TDANet
      # in_chan same as audio_bn_chan
      hid_chan: 512                       # FRCNN hidden channels
      upsampling_depth: 5
      shared: True
      repeats: 4
      norm_type: gLN
      act_type: PReLU
      kernel_size: 5
      stride: 2 
      n_head: 8
    
    video_params:
      video_net: TDANet
      # in_chan same as video_bn_chan
      hid_chan: 64
      upsampling_depth: 4
      shared: True
      repeats: 1
      norm_type: BatchNorm1d
      act_type: PReLU
      kernel_size: 3
      stride: 2
      n_head: 8

    fusion_params:
      fusion_type: ConcatFusion
      fusion_shared: True

    mask_generation_params:
      mask_act: ReLU
      
# Training config
training:
    gpus: [0,1,2,3,4,5,6]
    epochs: 200
    batch_size: 4
    num_workers: 8
    half_lr: yes
    early_stop: yes
    divide_lr_by: null
    online_mix: false
# Optim config
optim:
    optimizer: adamw
    lr: 0.001
    weight_decay: 0.1
# Sche config
sche:
    patience: 49
    factor: 0.5
# Data config
data:
    train_dir: data-preprocess/LRS2/tr
    valid_dir: data-preprocess/LRS2/cv
    nondefault_nsrc: 1
    sample_rate: 16000
    segment: 2.0
    normalize_audio: false
log:
    path: log/tmp
    pro_name: project
    exp_name: ctcnet_small_tdanet_08_03_2023
